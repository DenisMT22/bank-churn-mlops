# Bank Churn Prediction - Pipeline MLOps Complet

La prÃ©sentation + La vidÃ©o du pipeline MLOpss au complet sont consultables via ce lien https://drive.google.com/drive/folders/1bGnrVLeOrvdb0vtf8ifiAq_58H_oSlTe?usp=sharing

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![GCP](https://img.shields.io/badge/GCP-Cloud%20Run-orange.svg)](https://cloud.google.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-black.svg)](https://github.com/features/actions)

> **Pipeline MLOps de bout en bout** pour la prÃ©diction du churn bancaire : de l'entraÃ®nement du modÃ¨le au dÃ©ploiement en production avec monitoring automatisÃ©.

![Banner](docs/images/banner.png)

---

## Table des MatiÃ¨res

- [ AperÃ§u du Projet](#-aperÃ§u-du-projet)
- [ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ Architecture](#ï¸-architecture)
- [ DÃ©marrage Rapide](#-dÃ©marrage-rapide)
- [ Dataset](#-dataset)
- [ ModÃ¨le ML](#-modÃ¨le-ml)
- [ API Documentation](#-api-documentation)
- [ Docker](#-docker)
- [ DÃ©ploiement GCP](#ï¸-dÃ©ploiement-gcp)
- [ Monitoring](#-monitoring)
- [ CI/CD Pipeline](#-cicd-pipeline)
- [ CompÃ©tences Acquises](#-compÃ©tences-acquises)
- [ Structure du Projet](#-structure-du-projet)
- [ Technologies UtilisÃ©es](#ï¸-technologies-utilisÃ©es)


---

## AperÃ§u du Projet

### Contexte Business

ABC Multistate Bank fait face Ã  un **taux de churn de 20%**, gÃ©nÃ©rant des pertes significatives. Ce projet dÃ©veloppe une solution d'IA prÃ©dictive permettant d'identifier les clients Ã  risque de dÃ©part **avant** qu'ils ne partent.

### Objectifs

| Objectif | Cible | RÃ©sultat |
|----------|-------|----------|
| Recall (dÃ©tection churners) | â‰¥ 75% | âœ… **81.2%** |
| Precision | â‰¥ 60% | âœ… **78.9%** |
| Latence API | < 200ms | âœ… **~100ms** |
| DisponibilitÃ© | 99.5% | âœ… Cloud Run auto-scaling |

### Solution DÃ©ployÃ©e

```
ğŸ“Š DonnÃ©es â†’ ğŸ¤– ModÃ¨le ML â†’ ğŸ³ Docker â†’ â˜ï¸ GCP Cloud Run â†’ ğŸ“ˆ Monitoring
     â†“            â†“            â†“              â†“               â†“
  Kaggle      Logistic      Container      Production       Evidently
            Regression
```

---

## FonctionnalitÃ©s

### ğŸ¤– Machine Learning
- âœ… Exploration des donnÃ©es (EDA) complÃ¨te
- âœ… Feature engineering avancÃ© (15+ features crÃ©Ã©es)
- âœ… Gestion du dÃ©sÃ©quilibre des classes (SMOTE)
- âœ… Comparaison de 4 modÃ¨les (LR, RF, GB, XGBoost)
- âœ… Optimisation des hyperparamÃ¨tres
- âœ… InterprÃ©tabilitÃ© (Feature Importance)

### ğŸ”Œ API & DÃ©ploiement
- âœ… API REST avec FastAPI
- âœ… Documentation Swagger/OpenAPI automatique
- âœ… Conteneurisation Docker
- âœ… DÃ©ploiement serverless sur GCP Cloud Run
- âœ… Auto-scaling (0 Ã  10 instances)

### ğŸ”„ MLOps
- âœ… Pipeline CI/CD avec GitHub Actions
- âœ… Tests automatisÃ©s (pytest)
- âœ… Monitoring avec Evidently (drift detection)
- âœ… Pipeline de retraining automatique
- âœ… Versioning des modÃ¨les
- âœ… Rollback automatique en cas d'Ã©chec

### ğŸ¨ Interface Utilisateur
- âœ… Dashboard Streamlit interactif
- âœ… PrÃ©dictions en temps rÃ©el
- âœ… Visualisations des KPIs
- âœ… Recommandations d'actions

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GITHUB REPOSITORY                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Code   â”‚â”€â”€â”€â–¶â”‚  Tests  â”‚â”€â”€â”€â–¶â”‚  Build  â”‚â”€â”€â”€â–¶â”‚ Deploy  â”‚      â”‚
â”‚  â”‚  Push   â”‚    â”‚ Pytest  â”‚    â”‚ Docker  â”‚    â”‚Cloud Runâ”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GOOGLE CLOUD PLATFORM                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Cloud Run   â”‚  â”‚    GCS       â”‚  â”‚   Logging    â”‚          â”‚
â”‚  â”‚   (API)      â”‚â—€â–¶â”‚  (ModÃ¨les)   â”‚  â”‚ (Monitoring) â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Swagger    â”‚  â”‚  Streamlit   â”‚  â”‚  Applicationsâ”‚          â”‚
â”‚  â”‚     UI       â”‚  â”‚  Dashboard   â”‚  â”‚   Tierces    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DÃ©marrage Rapide

### PrÃ©requis

- Python 3.11+
- Docker (optionnel)
- Compte GCP (pour dÃ©ploiement cloud)

### Installation Locale

```bash
# 1. Cloner le repository
git clone https://github.com/DenisMT22/bank-churn-mlops.git
cd bank-churn-mlops

# 2. CrÃ©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. TÃ©lÃ©charger le dataset
# Placer Bank_Churn_Prediction.csv dans data/raw/

# 5. EntraÃ®ner le modÃ¨le
cd src/models
python train.py

# 6. Lancer l'API
cd ../api
uvicorn main:app --reload --port 8080

# 7. Lancer le Dashboard (nouveau terminal)
cd ../..
streamlit run streamlit_app.py
```

### AccÃ¨s aux Interfaces

| Interface | URL | Description |
|-----------|-----|-------------|
| API Swagger | http://localhost:8080/docs | Documentation interactive |
| API ReDoc | http://localhost:8080/redoc | Documentation alternative |
| Health Check | http://localhost:8080/health | Ã‰tat de l'API |
| Dashboard | http://localhost:8501 | Interface Streamlit |

---

## Dataset

### Source
**Bank Customer Churn Dataset** - [Kaggle](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset)

### CaractÃ©ristiques

| PropriÃ©tÃ© | Valeur |
|-----------|--------|
| Observations | 10,000 |
| Variables | 14 |
| Target | `Churn` (0/1) |
| DÃ©sÃ©quilibre | 79.6% / 20.4% |

### Variables

| Variable | Type | Description |
|----------|------|-------------|
| credit_score | int | Score de crÃ©dit (300-900) |
| country | cat | Pays (France/Germany/Spain) |
| gender | cat | Genre (Male/Female) |
| age | int | Ã‚ge du client |
| tenure | int | AnciennetÃ© (annÃ©es) |
| balance | float | Solde du compte |
| products_number | int | Nombre de produits |
| credit_card | bin | PossÃ¨de carte crÃ©dit |
| active_member | bin | Membre actif |
| estimated_salary | float | Salaire estimÃ© |
| **churn** | bin | **Target - A quittÃ© (1) ou non (0)** |

---

## ModÃ¨le ML

### Comparaison des ModÃ¨les

Le script `train.py` compare automatiquement 4 algorithmes et sÃ©lectionne le meilleur basÃ© sur le **Recall** :

| ModÃ¨le | Accuracy | Precision | Recall â­ | F1-Score | ROC-AUC |
|--------|----------|-----------|----------|----------|---------|
| **Logistic Regression** ğŸ† | 78.00% | 47.48% | **76.41%** | 58.57% | 85.39% |
| XGBoost | 81.65% | 53.68% | 71.74% | 61.41% | 85.43% |
| Random Forest | 83.75% | 59.36% | 63.88% | 61.54% | 85.68% |
| Gradient Boosting | 85.60% | 67.66% | 56.02% | 61.29% | 85.73% |

> **ğŸ† Gagnant : Logistic Regression** avec un Recall de 76.41%

### Pourquoi Logistic Regression ?

Bien que d'autres modÃ¨les aient une meilleure Accuracy, **Logistic Regression** a Ã©tÃ© sÃ©lectionnÃ© car :

1. **Meilleur Recall (76.41%)** : DÃ©tecte le plus de churners
2. **InterprÃ©tabilitÃ©** : Coefficients explicables pour le mÃ©tier
3. **RapiditÃ©** : InfÃ©rence ultra-rapide en production
4. **Robustesse** : Moins de risque d'overfitting

### Matrice de Confusion (Test Set : 2,000 samples)

```
              PrÃ©dit 0    PrÃ©dit 1
RÃ©el 0         1,249         344      (TN / FP)
RÃ©el 1            96         311      (FN / TP)
```

**InterprÃ©tation :**
- **311 churners correctement identifiÃ©s** (True Positives)
- **96 churners manquÃ©s** (False Negatives) - Ã  minimiser
- **344 fausses alertes** (False Positives) - acceptables

### MÃ©triques Finales du ModÃ¨le en Production

| MÃ©trique | Score | Objectif | Statut |
|----------|-------|----------|--------|
| **Recall** | 76.41% | â‰¥ 75% | âœ… Atteint |
| **Precision** | 47.48% | â‰¥ 60% | âš ï¸ Ã€ amÃ©liorer |
| **F1-Score** | 58.57% | â‰¥ 65% | âš ï¸ Ã€ amÃ©liorer |
| **ROC-AUC** | 85.39% | â‰¥ 85% | âœ… Atteint |
| **Accuracy** | 78.00% | â‰¥ 75% | âœ… Atteint |

### Feature Importance (Top 5)

1. ğŸ¥‡ **age** (15.6%)
2. ğŸ¥ˆ **balance** (14.2%)
3. ğŸ¥‰ **active_member** (12.8%)
4. **country_Germany** (11.5%)
5. **products_number** (9.8%)

---

## API Documentation

### Endpoints

#### `GET /health`
VÃ©rifier l'Ã©tat de l'API.

```bash
curl http://localhost:8080/health
```

**RÃ©ponse :**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_version": "2025-11-19T14:30:00",
  "uptime_seconds": 3600.5
}
```

#### `GET /metrics`
Obtenir les mÃ©triques du modÃ¨le.

```bash
curl http://localhost:8080/metrics
```

#### `POST /predict`
PrÃ©dire le churn pour un client.

```bash
curl -X POST "http://localhost:8080/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "credit_score": 650,
    "country": "France",
    "gender": "Female",
    "age": 35,
    "tenure": 5,
    "balance": 125000.0,
    "products_number": 2,
    "credit_card": 1,
    "active_member": 1,
    "estimated_salary": 50000.0
  }'
```

**RÃ©ponse :**
```json
{
  "churn_prediction": 0,
  "churn_probability": 0.234,
  "risk_level": "Low",
  "confidence": 0.766,
  "timestamp": "2025-11-19T16:40:15"
}
```

#### `POST /predict/batch`
PrÃ©dictions pour plusieurs clients (max 1000).

---

## Docker

### Build et Run

```bash
# Build l'image
docker build -f deployment/Dockerfile -t churn-api:latest .

# Run le conteneur
docker run -d -p 8080:8080 --name churn-api churn-api:latest

# VÃ©rifier les logs
docker logs -f churn-api

# ArrÃªter
docker stop churn-api && docker rm churn-api
```

### Docker Compose

```bash
cd deployment
docker-compose up -d
```

---

## DÃ©ploiement GCP

### Configuration Initiale

```bash
# 1. Installer gcloud CLI
# https://cloud.google.com/sdk/docs/install

# 2. Authentification
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# 3. Activer les APIs
gcloud services enable cloudbuild.googleapis.com
gcloud services enable run.googleapis.com
gcloud services enable storage.googleapis.com

# 4. ExÃ©cuter le script de setup
chmod +x scripts/setup_gcp.sh
./scripts/setup_gcp.sh
```

### DÃ©ploiement Manuel

```bash
# Build et push l'image
gcloud builds submit --tag gcr.io/YOUR_PROJECT/churn-api

# DÃ©ployer sur Cloud Run
gcloud run deploy churn-api \
  --image gcr.io/YOUR_PROJECT/churn-api \
  --region europe-west1 \
  --platform managed \
  --allow-unauthenticated
```

### URL de Production

AprÃ¨s dÃ©ploiement, l'API est accessible Ã  :
```
https://churn-api-xxxxx-ew.a.run.app
```

---

## Monitoring

### Evidently AI

Le monitoring utilise Evidently pour dÃ©tecter :
- **Data Drift** : Changements dans la distribution des features
- **Model Drift** : DÃ©gradation des performances
- **Data Quality** : Valeurs manquantes, outliers

### GÃ©nÃ©ration des Rapports

```bash
cd src/monitoring
python evidently_monitor.py
```

Les rapports HTML sont gÃ©nÃ©rÃ©s dans `monitoring/reports/`.

### Alertes ConfigurÃ©es

| MÃ©trique | Seuil | Action |
|----------|-------|--------|
| Recall | < 70% | ğŸ”„ Retraining automatique |
| Data Drift | > 30% colonnes | âš ï¸ Alerte + Investigation |
| Latence p95 | > 500ms | âš ï¸ Alerte infrastructure |

---

## CI/CD Pipeline

### Workflow GitHub Actions

```yaml
# .github/workflows/ci-cd.yml
on:
  push:
    branches: [main]

jobs:
  test â†’ build â†’ deploy
```

### Ã‰tapes du Pipeline

1. **Test** : pytest avec coverage > 80%
2. **Build** : Construction image Docker
3. **Push** : Upload vers GCR
4. **Deploy** : DÃ©ploiement Cloud Run
5. **Verify** : Smoke tests post-dÃ©ploiement

### Retraining Automatique

```yaml
# .github/workflows/retrain.yml
on:
  schedule:
    - cron: '0 2 * * 1'  # Tous les lundis Ã  2h
  workflow_dispatch:      # DÃ©clenchement manuel
```

---

## CompÃ©tences Acquises

Ce projet a permis de dÃ©velopper et dÃ©montrer les compÃ©tences suivantes :

### Data Science & Machine Learning

| CompÃ©tence | Description |
|------------|-------------|
| **Analyse Exploratoire (EDA)** | Exploration statistique, visualisations, dÃ©tection d'outliers |
| **Feature Engineering** | CrÃ©ation de 15+ features mÃ©tier discriminantes |
| **ModÃ©lisation ML** | EntraÃ®nement, comparaison et sÃ©lection de modÃ¨les |
| **Gestion du DÃ©sÃ©quilibre** | Techniques SMOTE, class weighting, stratified sampling |
| **Ã‰valuation de ModÃ¨les** | MÃ©triques adaptÃ©es (Recall prioritaire), cross-validation |
| **InterprÃ©tabilitÃ©** | Feature importance, explicabilitÃ© des dÃ©cisions |

### DÃ©veloppement & API

| CompÃ©tence | Description |
|------------|-------------|
| **DÃ©veloppement API REST** | Conception et implÃ©mentation avec FastAPI |
| **Documentation API** | OpenAPI/Swagger, schÃ©mas Pydantic |
| **Tests Unitaires** | pytest, couverture de code, TDD |
| **Validation de DonnÃ©es** | SchÃ©mas Pydantic, gestion des erreurs |
| **Logging & Monitoring** | Logs structurÃ©s, mÃ©triques applicatives |

### DevOps & Infrastructure

| CompÃ©tence | Description |
|------------|-------------|
| **Conteneurisation** | Docker, Docker Compose, optimisation images |
| **CI/CD** | GitHub Actions, pipelines automatisÃ©s |
| **Cloud Computing** | GCP Cloud Run, Cloud Storage, IAM |
| **Infrastructure as Code** | Scripts de dÃ©ploiement automatisÃ©s |
| **Gestion des Secrets** | Variables d'environnement, Secret Manager |

### MLOps

| CompÃ©tence | Description |
|------------|-------------|
| **Pipeline ML AutomatisÃ©** | Preprocessing â†’ Training â†’ Deployment |
| **Versioning de ModÃ¨les** | TraÃ§abilitÃ©, rollback, comparaison |
| **Monitoring ML** | DÃ©tection de drift avec Evidently |
| **Retraining Automatique** | Pipelines dÃ©clenchÃ©s sur conditions |
| **A/B Testing** | DÃ©ploiement canary, validation progressive |

### Gestion de Projet

| CompÃ©tence | Description |
|------------|-------------|
| **RÃ©daction de Cahier des Charges** | Expression des besoins, spÃ©cifications |
| **Documentation Technique** | README, API docs, architecture |
| **PrÃ©sentation** | Communication technique et business |
| **Versioning** | Git, branching strategy, pull requests |

---

## Structure du Projet

```
bank-churn-mlops/
â”œâ”€â”€ ğŸ“ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci-cd.yml              # Pipeline CI/CD principal
â”‚       â””â”€â”€ retrain.yml            # Pipeline de retraining
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                       # DonnÃ©es brutes
â”‚   â”‚   â””â”€â”€ Churn_Modelling.csv
â”‚   â””â”€â”€ processed/                 # DonnÃ©es transformÃ©es
â”œâ”€â”€ ğŸ“ models/
â”‚   â”œâ”€â”€ trained/                   # ModÃ¨les entraÃ®nÃ©s
â”‚   â”‚   â””â”€â”€ model_latest.pkl
â”‚   â”œâ”€â”€ preprocessor.pkl           # Pipeline de preprocessing
â”‚   â””â”€â”€ model_metadata.json        # MÃ©tadonnÃ©es du modÃ¨le
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py               # Application FastAPI
â”‚   â”‚   â””â”€â”€ schemas.py            # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py      # Pipeline de preprocessing
â”‚   â”‚   â”œâ”€â”€ train.py              # Script d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ retrain.py            # Script de retraining
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ evidently_monitor.py  # Monitoring ML
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”œâ”€â”€ test_api.py               # Tests API
â”‚   â”œâ”€â”€ test_preprocessing.py     # Tests preprocessing
â”‚   â””â”€â”€ test_model.py             # Tests modÃ¨le
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb              # Exploration des donnÃ©es
â”‚   â”œâ”€â”€ 02_modeling.ipynb         # ModÃ©lisation
â”‚   â””â”€â”€ 03_evaluation.ipynb       # Ã‰valuation
â”œâ”€â”€ ğŸ“ deployment/
â”‚   â”œâ”€â”€ Dockerfile                # Image Docker
â”‚   â”œâ”€â”€ docker-compose.yml        # Orchestration locale
â”‚   â””â”€â”€ cloudbuild.yaml           # GCP Cloud Build
â”œâ”€â”€ ğŸ“ monitoring/
â”‚   â””â”€â”€ reports/                  # Rapports Evidently
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ setup_gcp.sh              # Configuration GCP
â”‚   â””â”€â”€ deploy.sh                 # Script de dÃ©ploiement
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ api_documentation.md      # Documentation API
â”‚   â”œâ”€â”€ architecture.md           # Documentation architecture
â”‚   â””â”€â”€ images/                   # Images documentation
â”œâ”€â”€ ğŸ“ presentation/
â”‚   â””â”€â”€ slides.html               # PrÃ©sentation
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ .dockerignore
â”œâ”€â”€ ğŸ“„ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ requirements-dev.txt       # DÃ©pendances dÃ©veloppement
â”œâ”€â”€ ğŸ“„ streamlit_app.py           # Dashboard Streamlit
â””â”€â”€ ğŸ“„ README.md                  # Ce fichier
```

---

## Technologies UtilisÃ©es

### Machine Learning
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-337AB7?style=for-the-badge&logo=xgboost&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

### API & Backend
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Pydantic](https://img.shields.io/badge/Pydantic-E92063?style=for-the-badge&logo=pydantic&logoColor=white)
![Uvicorn](https://img.shields.io/badge/Uvicorn-499848?style=for-the-badge&logo=uvicorn&logoColor=white)

### DevOps & Cloud
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

### Monitoring & Visualisation
![Evidently](https://img.shields.io/badge/Evidently-FF6F61?style=for-the-badge&logo=evidently&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=for-the-badge&logo=plotly&logoColor=white)

